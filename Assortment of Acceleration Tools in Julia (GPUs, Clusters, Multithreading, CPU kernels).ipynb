{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An Assortment of Julia Interfaces for Accelerators\n",
    "\n",
    "## GPUs, Clusters, Multithreading, and fancy tools for old boring CPUs\n",
    "\n",
    "- Tools for interfacing with hardware accelerators\n",
    "- Tools for Cluster multi-processing, or single node multi-threading\n",
    "- Tools to make the best use of your CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools # You should always use this library\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia GPU interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "`CUDA` for Nvidia hardware is well supported. `AMDGPU` for AMD hardware is not reliable yet.\n",
    "\n",
    "See also: [The Julia GPU documentation](https://juliagpu.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AMDGPU # For AMD GPUs, experimental, not always worth it\n",
    "toGPU = ROCArray;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA # For Nvidia GPUs, fairly mature \n",
    "toGPU = CuArray;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using oneAPI # An Intel attempt at unified driver landscape, not used by many\n",
    "toGPU = oneArray;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also some stuff about TPUs and other special hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "N = 5000\n",
    "t = Float32\n",
    "A = rand(t,N,N)\n",
    "B = rand(t,N,N)\n",
    "C = rand(t,N,N)\n",
    "Ag = toGPU(A)\n",
    "Bg = toGPU(B)\n",
    "Cg = toGPU(C);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "@btime mul!(C,A,B)\n",
    "@btime mul!(Cg,Ag,Bg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = 100_000_000\n",
    "t = Float32\n",
    "a = rand(t,n)\n",
    "b = rand(t,n)\n",
    "c = rand(t,n)\n",
    "ag = toGPU(a)\n",
    "bg = toGPU(b)\n",
    "cg = toGPU(c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  468.857 ms (4 allocations: 128 bytes)\n",
      "  11.442 ms (126 allocations: 6.02 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime c .= sin.(b .* a)\n",
    "@btime cg .= sin.(bg .* ag);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GPU ODE example\n",
    "\n",
    "See also: [DifferentialEquations.jl FAQ on GPU usage](https://diffeq.sciml.ai/stable/basics/faq/#GPUs,-multithreading-and-distributed-computation-support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OrdinaryDiffEq\n",
    "\n",
    "n = 1000\n",
    "t = Float32\n",
    "u0 = toGPU(rand(t,n))\n",
    "A  = toGPU(randn(t,n,n))\n",
    "f(du,u,p,t)  = mul!(du,A,u)\n",
    "\n",
    "tspan = (0.0,1.0)\n",
    "tspan = t.(tspan)\n",
    "\n",
    "prob = ODEProblem(f,u0,tspan)\n",
    "solver_algo = Tsit5() # You might want to be careful with the choice of algo\n",
    "sol = solve(prob,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia Distributed Computing interface\n",
    "\n",
    "Julia includes tools to run computation on clusters of computers\n",
    "\n",
    "- [Julia manual on distributed capabilities](https://docs.julialang.org/en/v1/manual/distributed-computing/)\n",
    "- [The Base distrubuted computing library `Distrubuted.jl`](https://docs.julialang.org/en/v1/stdlib/Distributed/)\n",
    "- [`DistributedArrays.jl` for gigantic arrays split between devices](https://juliaparallel.github.io/DistributedArrays.jl/stable/)\n",
    "- [A toy example you can run on a single computer](https://juliaparallel.github.io/DistributedArrays.jl/stable/#Example-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using Distributed\n",
    "\n",
    "# Adding 3 processes to the cluster\n",
    "addprocs(3)\n",
    "\n",
    "# Running setup code on each process\n",
    "@everywhere using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2, 1, 11, nothing)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requesting an arbitrary worker to perform a computation\n",
    "# This is async / non-blocking command\n",
    "references_to_computations = @spawnat :any norm(rand(1000))/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01793967931340792"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the result\n",
    "computation_results = fetch(references_to_computations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(@spawnat :any myid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "On worker 2:\nUndefVarError: #work_function not defined\nStacktrace:\n  [1] \u001b[0m\u001b[1mdeserialize_datatype\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:1280\u001b[0m\n  [2] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:827\u001b[0m\n  [3] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:774\u001b[0m\n  [4] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:834\u001b[0m\n  [5] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:774\u001b[0m\u001b[90m [inlined]\u001b[39m\n  [6] \u001b[0m\u001b[1mdeserialize_msg\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mmessages.jl:87\u001b[0m\n  [7] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4messentials.jl:708\u001b[0m\u001b[90m [inlined]\u001b[39m\n  [8] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4messentials.jl:706\u001b[0m\u001b[90m [inlined]\u001b[39m\n  [9] \u001b[0m\u001b[1mmessage_handler_loop\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mprocess_messages.jl:169\u001b[0m\n [10] \u001b[0m\u001b[1mprocess_tcp_streams\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mprocess_messages.jl:126\u001b[0m\n [11] \u001b[0m\u001b[1m#99\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mtask.jl:406\u001b[0m",
     "output_type": "error",
     "traceback": [
      "On worker 2:\nUndefVarError: #work_function not defined\nStacktrace:\n  [1] \u001b[0m\u001b[1mdeserialize_datatype\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:1280\u001b[0m\n  [2] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:827\u001b[0m\n  [3] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:774\u001b[0m\n  [4] \u001b[0m\u001b[1mhandle_deserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:834\u001b[0m\n  [5] \u001b[0m\u001b[1mdeserialize\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Serialization/src/\u001b[39m\u001b[90;4mSerialization.jl:774\u001b[0m\u001b[90m [inlined]\u001b[39m\n  [6] \u001b[0m\u001b[1mdeserialize_msg\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mmessages.jl:87\u001b[0m\n  [7] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4messentials.jl:708\u001b[0m\u001b[90m [inlined]\u001b[39m\n  [8] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4messentials.jl:706\u001b[0m\u001b[90m [inlined]\u001b[39m\n  [9] \u001b[0m\u001b[1mmessage_handler_loop\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mprocess_messages.jl:169\u001b[0m\n [10] \u001b[0m\u001b[1mprocess_tcp_streams\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mprocess_messages.jl:126\u001b[0m\n [11] \u001b[0m\u001b[1m#99\u001b[22m\n\u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mtask.jl:406\u001b[0m",
      "",
      "Stacktrace:",
      "  [1] (::Base.var\"#837#839\")(x::Task)",
      "    @ Base ./asyncmap.jl:177",
      "  [2] foreach(f::Base.var\"#837#839\", itr::Vector{Any})",
      "    @ Base ./abstractarray.jl:2141",
      "  [3] maptwice(wrapped_f::Function, chnl::Channel{Any}, worker_tasks::Vector{Any}, c::Vector{Int64})",
      "    @ Base ./asyncmap.jl:177",
      "  [4] wrap_n_exec_twice",
      "    @ ./asyncmap.jl:153 [inlined]",
      "  [5] #async_usemap#822",
      "    @ ./asyncmap.jl:103 [inlined]",
      "  [6] #asyncmap#821",
      "    @ ./asyncmap.jl:81 [inlined]",
      "  [7] pmap(f::Function, p::WorkerPool, c::Vector{Int64}; distributed::Bool, batch_size::Int64, on_error::Nothing, retry_delays::Vector{Any}, retry_check::Nothing)",
      "    @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/pmap.jl:126",
      "  [8] pmap(f::Function, p::WorkerPool, c::Vector{Int64})",
      "    @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/pmap.jl:101",
      "  [9] pmap(f::Function, c::Vector{Int64}; kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/pmap.jl:156",
      " [10] pmap(f::Function, c::Vector{Int64})",
      "    @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/pmap.jl:156",
      " [11] top-level scope",
      "    @ In[51]:2",
      " [12] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "work_function(n) = norm(rand(n))/n\n",
    "pmap(work_function, [100,10000,900,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.055641432124401556\n",
       " 0.005791920133203985\n",
       " 0.01904387958085956\n",
       " 0.09539130437047112"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere work_function(n) = norm(rand(n))/n\n",
    "pmap(work_function, [100,10000,900,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[`DistributedArrays.jl`](https://juliaparallel.github.io/DistributedArrays.jl/) can be used to create arrays that are distributed among many cluster nodes. It works seamlessly and virtually all Julia functions work on these arrays as if they were local arrays (or GPU arrays). However, for it to work fast, you need to put a lot of thought into exactly how the array is going to be partitioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Julia Multithreading interface\n",
    "\n",
    "You need to start Julia with the command `julia --threads=N` for N threads or `--threads=auto` to automatically use all CPU cores.\n",
    "\n",
    "See also:\n",
    "\n",
    "- [Official Blog post on the topic](https://julialang.org/blog/2019/07/multithreading/)\n",
    "- [Manual](https://docs.julialang.org/en/v1/manual/multi-threading/)\n",
    "- [Multithreading module documentation](https://docs.julialang.org/en/v1/base/multi-threading/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Base.Threads\n",
    "\n",
    "# Check how many threads are available;\n",
    "# These examples will not be interesting on a single thread\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `@threads` macro lets you automatically multithread a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zeros(10)\n",
    "@threads for i in 1:10\n",
    "   a[i] = threadid()\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "some_interesting_computation(p) = sin(p)^2\n",
    "\n",
    "@threads for parameter in [0.5,0.6,0.7]\n",
    "   println(some_interesting_computation(parameter))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `ThreadTools` library has some extra convenience functions. Unlike other libraries discussed here, it is rather small and it might be superseeded by functionality included in base Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ThreadTools # A small independent package / some of this might end up in base Julia\n",
    "\n",
    "tmap(some_interesting_computation, [0.5, 0.6, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Threading is simple and great if the loop iterations are independent, but it might cause immense suffering if you are not careful with data dependencies.\n",
    "\n",
    "FYI, assigning to a particular index in an array works fine in threads, so just do not use `push!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test()\n",
    "    a = []\n",
    "    @threads for i in 1:100000\n",
    "        push!(a,1)\n",
    "    end\n",
    "    length(a)\n",
    "end\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fast Loops and Tensor Operations (on CPUs and maybe more)\n",
    "\n",
    "This will get pretty low level..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Low haging fruits\n",
    "\n",
    "- [Julia Performance Tips](https://docs.julialang.org/en/v1/manual/performance-tips/)\n",
    "- [`@inbounds`, `@fastmath`, `@simd`](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-annotations)\n",
    "- [`StaticArray`](https://github.com/JuliaArrays/StaticArrays.jl) if you have many small arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.447 μs (1 allocation: 16 bytes)\n"
     ]
    }
   ],
   "source": [
    "x = rand(10000)\n",
    "y = rand(10000)\n",
    "\n",
    "function vecprod1(x,y)\n",
    "    s = 0.0\n",
    "    for i in eachindex(x)\n",
    "        s += x[i]*y[i]\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "@btime vecprod1(x,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.822 μs (1 allocation: 16 bytes)\n"
     ]
    }
   ],
   "source": [
    "function vecprod2(x,y)\n",
    "    s = 0.0\n",
    "    @inbounds @simd for i in eachindex(x)\n",
    "        s += x[i]*y[i]\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "@btime vecprod2(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fancy Tensor Libraries\n",
    "\n",
    "Mostly based around [LoopVectorization.jl](https://github.com/chriselrod/LoopVectorization.jl).\n",
    "\n",
    "| Julia Package                                                    | CPU | GPU | Note                        |\n",
    "| ---------------------------------------------------------------- | --- | --- |:--------------------------- |\n",
    "| [GemmKernels.jl](https://github.com/JuliaGPU/GemmKernels.jl)     | No  | Yes | the fastest CPU performance |\n",
    "| [Octavian.jl](https://github.com/JuliaLinearAlgebra/Octavian.jl) | Yes | No  | the fastest CPU performance |\n",
    "| [Tullio.jl](https://github.com/mcabbott/Tullio.jl)               | Yes | Yes | the most flexible           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using Tullio\n",
    "\n",
    "@tullion A[i,j] = B[i,k]*C[k,j]\n",
    "\n",
    "@tullio M[x,y,c] := N[x+i, y+j,c] * K[i,j]     # sum over i,j, and create M\n",
    "\n",
    "@tullio S[x] = P[x,y] * log(Q[x,y] / R[y])     # sum over y, and write into S\n",
    "\n",
    "@tullio A[i,j] += B[i,k,l] * C[l,j] * D[k,j]   # sum over k,l, and add to values in A\n",
    "\n",
    "@tullio (*) Z[j] := X[ind[k],j] * exp(-Y[k])   # product over k"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
